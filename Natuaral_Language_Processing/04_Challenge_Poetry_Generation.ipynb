{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTguFckTEDWd"
   },
   "source": [
    "# Poetry generation challenge\n",
    "\n",
    "This notebook serves as a challenge on how to create poetry like Shakespeare by leveraging RNNs(LSTMs). We'll be using the Shakerpeare poetry as the training data and then use the trained network to predict the next words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9mW3Mt2q5kL2",
    "outputId": "2d566f21-b471-4e35-8847-959a48d223a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "##import the required libraries and APIs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFhZpNjHoxSt"
   },
   "source": [
    "## Step 1: Create a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CwT0yxfRgZY_",
    "outputId": "73f62b92-1b5a-4364-8ceb-da79315aa7bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-08-21 16:13:58--  https://raw.githubusercontent.com/dswh/lil_nlp_with_tensorflow/main/sonnets.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 29658 (29K) [text/plain]\n",
      "Saving to: ‘/tmp/sonnet.txt’\n",
      "\n",
      "\r",
      "/tmp/sonnet.txt       0%[                    ]       0  --.-KB/s               \r",
      "/tmp/sonnet.txt     100%[===================>]  28.96K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-08-21 16:13:58 (73.2 MB/s) - ‘/tmp/sonnet.txt’ saved [29658/29658]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##download data from this url\n",
    "!wget --no-check-certificate \\\n",
    "    https://raw.githubusercontent.com/dswh/lil_nlp_with_tensorflow/main/sonnets.txt \\\n",
    "    -O /tmp/sonnet.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0JnENSlqBAH",
    "outputId": "f7073f54-60f4-45c3-b6cb-b3024b1f68fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28893\n"
     ]
    }
   ],
   "source": [
    "##printing the text\n",
    "shakespeare_text = open('/tmp/sonnet.txt').read()\n",
    "print(len(shakespeare_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "od13s5hUqA27"
   },
   "outputs": [],
   "source": [
    "##create corpus by lowering the letters and splitting the text by \\n\n",
    "corpus = shakespeare_text.lower().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1Z5IdaMqjLd"
   },
   "source": [
    "## Set up the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gIQifsC7qAtK"
   },
   "outputs": [],
   "source": [
    "##set up tokenizer\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aAoHN0Ar01tt",
    "outputId": "0702d652-1cb7-4b9c-8003-dcda092ce93c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1, 'the': 2, 'to': 3, 'thou': 4, 'in': 5, 'my': 6, 'of': 7, 'i': 8, 'thy': 9, 'that': 10, 'with': 11, 'thee': 12, 'for': 13, 'but': 14, 'not': 15, 'a': 16, 'love': 17, 'be': 18, 'all': 19, 'me': 20, 'when': 21, 'so': 22, 'by': 23, 'then': 24, 'is': 25, 'which': 26, 'as': 27, 'this': 28, 'from': 29, 'his': 30, 'self': 31, 'do': 32, 'thine': 33, 'it': 34, 'on': 35, 'art': 36, 'if': 37, 'eyes': 38, 'more': 39, 'or': 40, 'beauty': 41, 'mine': 42, 'doth': 43, 'you': 44, 'your': 45, 'time': 46, 'sweet': 47, 'make': 48, 'one': 49, 'where': 50, 'their': 51, 'fair': 52, 'her': 53, 'are': 54, 'yet': 55, 'day': 56, 'what': 57, 'see': 58, 'who': 59, 'than': 60, 'can': 61, 'should': 62, 'own': 63, 'shall': 64, 'how': 65, 'no': 66, 'hath': 67, 'will': 68, 'were': 69, 'live': 70, 'those': 71, 'him': 72, 'let': 73, 'may': 74, 'o': 75, 'night': 76, \"love's\": 77, 'now': 78, 'world': 79, 'she': 80, 'nor': 81, 'they': 82, \"beauty's\": 83, 'dost': 84, 'he': 85, 'give': 86, 'eye': 87, 'still': 88, 'such': 89, 'thought': 90, 'look': 91, 'like': 92, 'have': 93, 'bright': 94, 'an': 95, 'old': 96, 'must': 97, 'every': 98, 'though': 99, 'well': 100, 'many': 101, 'at': 102, 'even': 103, 'heart': 104, 'say': 105, 'face': 106, 'some': 107, 'age': 108, 'alone': 109, 'show': 110, 'ten': 111, 'youth': 112, 'most': 113, 'would': 114, 'men': 115, 'am': 116, 'die': 117, 'too': 118, 'being': 119, 'praise': 120, 'much': 121, 'new': 122, 'form': 123, 'why': 124, 'lives': 125, 'times': 126, 'each': 127, 'happy': 128, 'life': 129, 'hast': 130, 'honour': 131, 'dear': 132, 'heaven': 133, 'them': 134, 'long': 135, 'these': 136, 'both': 137, 'bear': 138, 'lies': 139, 'worth': 140, 'days': 141, 'shame': 142, 'use': 143, 'child': 144, 'made': 145, 'tell': 146, 'another': 147, 'whose': 148, 'through': 149, 'beauteous': 150, 'gone': 151, 'gentle': 152, 'did': 153, 'there': 154, 'death': 155, 'sight': 156, 'thyself': 157, 'joy': 158, 'true': 159, 'parts': 160, 'prove': 161, 'change': 162, 'decay': 163, 'whom': 164, 'best': 165, \"time's\": 166, 'other': 167, 'find': 168, 'stars': 169, 'earth': 170, 'till': 171, 'muse': 172, 'sun': 173, 'myself': 174, 'might': 175, 'tender': 176, 'fresh': 177, 'treasure': 178, \"'\": 179, 'glass': 180, 'back': 181, 'shalt': 182, 'single': 183, 'upon': 184, 'hours': 185, \"summer's\": 186, 'shouldst': 187, 'up': 188, 'way': 189, 'sweets': 190, 'war': 191, 'mind': 192, 'end': 193, 'since': 194, 'again': 195, 'eternal': 196, 'good': 197, 'fortune': 198, 'date': 199, 'thing': 200, 'state': 201, 'rich': 202, 'before': 203, 'lines': 204, 'verse': 205, 'compare': 206, 'lose': 207, 'things': 208, \"heaven's\": 209, 'wit': 210, 'loving': 211, 'thoughts': 212, 'clouds': 213, 'woe': 214, 'friend': 215, 'loss': 216, 'two': 217, 'our': 218, 'loves': 219, 'take': 220, 'we': 221, 'desire': 222, 'increase': 223, 'abundance': 224, 'waste': 225, 'else': 226, 'due': 227, 'brow': 228, 'proud': 229, 'blood': 230, 'cold': 231, 'repair': 232, 'calls': 233, 'lovely': 234, 'windows': 235, 'despite': 236, 'golden': 237, \"nature's\": 238, 'nothing': 239, 'great': 240, 'nature': 241, 'leave': 242, 'unused': 243, 'summer': 244, 'leaves': 245, \"o'er\": 246, 'was': 247, 'flowers': 248, 'substance': 249, 'place': 250, 'happier': 251, 'living': 252, \"death's\": 253, 'light': 254, 'head': 255, 'looks': 256, 'heavenly': 257, 'son': 258, 'wilt': 259, 'none': 260, 'fear': 261, 'ah': 262, 'keep': 263, 'any': 264, 'hate': 265, \"'gainst\": 266, 'fast': 267, 'mayst': 268, 'without': 269, 'store': 270, 'brave': 271, 'barren': 272, 'takes': 273, 'longer': 274, 'against': 275, 'yourself': 276, 'rage': 277, 'read': 278, 'shows': 279, 'out': 280, 'stay': 281, 'rhyme': 282, 'stand': 283, 'wish': 284, 'painted': 285, 'pen': 286, 'come': 287, 'write': 288, 'truth': 289, 'sometime': 290, 'shade': 291, 'swift': 292, 'draw': 293, \"woman's\": 294, 'false': 295, \"women's\": 296, 'first': 297, 'air': 298, 'breast': 299, 'therefore': 300, 'ill': 301, 'part': 302, 'seem': 303, 'grace': 304, 'buried': 305, \"remov'd\": 306, 'duty': 307, 'poor': 308, 'toil': 309, 'far': 310, 'shadow': 311, 'view': 312, 'disgrace': 313, 'friends': 314, 'think': 315, 'break': 316, 'moan': 317, 'dead': 318, 'better': 319, 'grief': 320, 'bring': 321, 'twain': 322, 'although': 323, 'sake': 324, 'thereby': 325, 'never': 326, 'decease': 327, 'heir': 328, 'memory': 329, 'making': 330, \"world's\": 331, 'ornament': 332, 'within': 333, 'bud': 334, 'churl': 335, 'grave': 336, 'deep': 337, \"tatter'd\": 338, 'held': 339, 'lusty': 340, \"'this\": 341, 'sum': 342, 'count': 343, 'excuse': 344, 'mother': 345, 'husbandry': 346, 'tomb': 347, 'stop': 348, 'posterity': 349, \"mother's\": 350, 'prime': 351, \"remember'd\": 352, 'image': 353, 'spend': 354, 'gives': 355, 'lends': 356, 'abuse': 357, 'bounteous': 358, 'canst': 359, 'having': 360, 'deceive': 361, 'work': 362, 'frame': 363, 'gaze': 364, 'same': 365, 'hideous': 366, 'winter': 367, 'confounds': 368, 'sap': 369, 'checked': 370, 'quite': 371, 'left': 372, 'effect': 373, 'remembrance': 374, \"distill'd\": 375, \"winter's\": 376, 'hand': 377, 'ere': 378, 'pay': 379, 'breed': 380, 'could': 381, 'lo': 382, 'gracious': 383, 'resembling': 384, 'strong': 385, 'pilgrimage': 386, 'weary': 387, \"unlook'd\": 388, 'unless': 389, 'music': 390, 'hear': 391, 'delights': 392, \"lov'st\": 393, \"receiv'st\": 394, 'pleasure': 395, 'sweetly': 396, 'chide': 397, 'sing': 398, 'song': 399, 'sings': 400, 'wail': 401, 'widow': 402, 'weep': 403, 'shape': 404, 'others': 405, 'bosom': 406, 'commits': 407, \"belov'd\": 408, \"possess'd\": 409, 'chief': 410, 'kind': 411, 'least': 412, \"grow'st\": 413, 'call': 414, 'away': 415, 'rude': 416, 'gave': 417, 'behold': 418, 'past': 419, 'white': 420, 'green': 421, 'borne': 422, 'go': 423, 'themselves': 424, 'grow': 425, 'save': 426, 'hence': 427, 'yours': 428, 'here': 429, 'lease': 430, 'after': 431, 'know': 432, 'had': 433, 'father': 434, 'pluck': 435, 'rain': 436, 'wouldst': 437, 'huge': 438, 'stage': 439, 'nought': 440, 'height': 441, 'conceit': 442, 'blessed': 443, 'drawn': 444, 'skill': 445, 'believe': 446, 'knows': 447, 'numbers': 448, 'touches': 449, 'less': 450, 'tongue': 451, 'antique': 452, 'shake': 453, 'shines': 454, 'gold': 455, 'course': 456, 'breathe': 457, 'fierce': 458, 'glad': 459, 'wide': 460, 'wrong': 461, 'theirs': 462, 'gilding': 463, 'man': 464, \"men's\": 465, 'woman': 466, 'wrought': 467, 'purpose': 468, 'rehearse': 469, 'moon': 470, 'cover': 471, 'dumb': 472, 'silent': 473, 'painter': 474, \"'tis\": 475, 'done': 476, 'want': 477, 'public': 478, 'boast': 479, 'whilst': 480, 'glory': 481, 'once': 482, 'rest': 483, 'send': 484, 'hope': 485, \"soul's\": 486, 'worthy': 487, 'respect': 488, 'limbs': 489, 'travel': 490, 'abide': 491, 'looking': 492, 'sightless': 493, 'hung': 494, 'thus': 495, \"oppress'd\": 496, \"either's\": 497, 'please': 498, 'flatter': 499, 'sorrows': 500, \"man's\": 501, 'contented': 502, 'wealth': 503, 'sad': 504, 'while': 505, 'birth': 506, 'brought': 507, 'full': 508, 'cloud': 509, 'stain': 510, 'forth': 511, 'cross': 512, 'tears': 513, 'deeds': 514, 'sins': 515, 'thief': 516, 'sourly': 517, 'remain': 518, 'spite': 519, 'steal': 520, 'delight': 521, 'name': 522, 'lame': 523, 'cannot': 524, 'slight': 525, 'leisure': 526, 'hadst': 527, 'absent': 528, 'sleep': 529, 'dreams': 530, 'heavy': 531, 'nights': 532, 'elements': 533, 'fairest': 534, 'creatures': 535, 'rose': 536, 'riper': 537, 'contracted': 538, \"feed'st\": 539, \"light's\": 540, 'flame': 541, 'substantial': 542, 'fuel': 543, 'famine': 544, 'foe': 545, 'cruel': 546, 'only': 547, 'herald': 548, 'gaudy': 549, 'spring': 550, 'buriest': 551, 'content': 552, \"mak'st\": 553, 'niggarding': 554, 'pity': 555, 'glutton': 556, 'eat': 557, 'ii': 558, 'forty': 559, 'winters': 560, 'besiege': 561, 'dig': 562, 'trenches': 563, 'field': 564, \"youth's\": 565, 'livery': 566, 'gazed': 567, 'weed': 568, 'small': 569, 'asked': 570, 'sunken': 571, 'eating': 572, 'thriftless': 573, \"deserv'd\": 574, 'couldst': 575, 'answer': 576, 'proving': 577, 'succession': 578, 'warm': 579, \"feel'st\": 580, 'iii': 581, 'viewest': 582, 'renewest': 583, 'beguile': 584, 'unbless': 585, \"unear'd\": 586, 'womb': 587, 'disdains': 588, 'tillage': 589, 'fond': 590, 'april': 591, 'wrinkles': 592, 'dies': 593, 'iv': 594, 'unthrifty': 595, 'loveliness': 596, 'legacy': 597, 'bequest': 598, 'lend': 599, 'frank': 600, 'free': 601, 'niggard': 602, 'largess': 603, 'given': 604, 'profitless': 605, 'usurer': 606, 'sums': 607, 'traffic': 608, 'acceptable': 609, 'audit': 610, 'tombed': 611, 'used': 612, \"th'\": 613, 'executor': 614, 'v': 615, 'dwell': 616, 'play': 617, 'tyrants': 618, 'very': 619, 'unfair': 620, 'fairly': 621, 'excel': 622, 'resting': 623, 'leads': 624, 'frost': 625, 'snowed': 626, 'bareness': 627, 'distillation': 628, 'liquid': 629, 'prisoner': 630, 'pent': 631, 'walls': 632, 'bereft': 633, 'meet': 634, 'leese': 635, 'vi': 636, 'ragged': 637, 'deface': 638, 'vial': 639, \"kill'd\": 640, 'forbidden': 641, 'usury': 642, 'happies': 643, 'willing': 644, 'loan': 645, \"that's\": 646, \"refigur'd\": 647, 'depart': 648, 'leaving': 649, \"will'd\": 650, 'conquest': 651, 'worms': 652, 'vii': 653, 'orient': 654, 'lifts': 655, 'burning': 656, 'under': 657, 'homage': 658, 'appearing': 659, 'serving': 660, 'sacred': 661, 'majesty': 662, \"climb'd\": 663, 'steep': 664, 'hill': 665, 'middle': 666, 'mortal': 667, 'adore': 668, 'attending': 669, 'highmost': 670, 'pitch': 671, 'car': 672, 'feeble': 673, 'reeleth': 674, \"'fore\": 675, 'duteous': 676, 'converted': 677, 'low': 678, 'tract': 679, 'outgoing': 680, 'noon': 681, 'diest': 682, 'get': 683, 'viii': 684, \"hear'st\": 685, 'sadly': 686, 'gladly': 687, 'annoy': 688, 'concord': 689, 'tuned': 690, 'sounds': 691, 'unions': 692, 'married': 693, 'offend': 694, 'ear': 695, 'singleness': 696, 'mark': 697, 'string': 698, 'husband': 699, 'strikes': 700, 'mutual': 701, 'ordering': 702, 'sire': 703, 'pleasing': 704, 'note': 705, 'speechless': 706, 'seeming': 707, \"'thou\": 708, 'ix': 709, 'wet': 710, \"widow's\": 711, \"consum'st\": 712, 'issueless': 713, 'hap': 714, 'makeless': 715, 'wife': 716, 'behind': 717, 'private': 718, \"children's\": 719, \"husband's\": 720, 'unthrift': 721, 'shifts': 722, 'enjoys': 723, 'kept': 724, 'user': 725, 'destroys': 726, 'toward': 727, 'sits': 728, 'himself': 729, \"murd'rous\": 730, 'x': 731, 'deny': 732, \"bear'st\": 733, 'unprovident': 734, 'grant': 735, 'evident': 736, 'murderous': 737, \"stick'st\": 738, 'conspire': 739, 'seeking': 740, 'roof': 741, 'ruinate': 742, 'fairer': 743, \"lodg'd\": 744, 'presence': 745, 'hearted': 746, 'xi': 747, 'wane': 748, 'departest': 749, 'youngly': 750, \"bestow'st\": 751, 'convertest': 752, 'herein': 753, 'wisdom': 754, 'folly': 755, 'minded': 756, 'cease': 757, 'threescore': 758, 'year': 759, 'harsh': 760, 'featureless': 761, 'barrenly': 762, 'perish': 763, \"endow'd\": 764, 'gift': 765, 'bounty': 766, 'cherish': 767, \"carv'd\": 768, 'seal': 769, 'meant': 770, 'print': 771, 'copy': 772, 'xii': 773, 'clock': 774, 'tells': 775, 'sunk': 776, 'violet': 777, 'sable': 778, 'curls': 779, 'silvered': 780, 'lofty': 781, 'trees': 782, 'erst': 783, 'heat': 784, 'canopy': 785, 'herd': 786, 'girded': 787, 'sheaves': 788, 'bier': 789, 'bristly': 790, 'beard': 791, 'question': 792, 'among': 793, 'wastes': 794, 'beauties': 795, 'forsake': 796, 'scythe': 797, 'defence': 798, 'xiii': 799, 'coming': 800, 'prepare': 801, 'semblance': 802, 'hold': 803, 'determination': 804, \"yourself's\": 805, 'issue': 806, 'lets': 807, 'house': 808, 'fall': 809, 'uphold': 810, 'stormy': 811, 'gusts': 812, 'unthrifts': 813, 'xiv': 814, 'judgement': 815, 'methinks': 816, 'astronomy': 817, 'evil': 818, 'luck': 819, 'plagues': 820, 'dearths': 821, \"seasons'\": 822, 'quality': 823, 'brief': 824, 'minutes': 825, 'pointing': 826, 'thunder': 827, 'wind': 828, 'princes': 829, 'oft': 830, 'predict': 831, 'knowledge': 832, 'derive': 833, 'constant': 834, \"'truth\": 835, 'together': 836, 'thrive': 837, \"convert'\": 838, 'prognosticate': 839, \"'thy\": 840, \"truth's\": 841, 'doom': 842, 'xv': 843, 'consider': 844, 'grows': 845, 'holds': 846, 'perfection': 847, 'little': 848, 'moment': 849, 'presenteth': 850, 'whereon': 851, 'secret': 852, 'influence': 853, 'comment': 854, 'perceive': 855, 'plants': 856, 'cheered': 857, 'sky': 858, 'vaunt': 859, 'youthful': 860, 'decrease': 861, 'wear': 862, 'inconstant': 863, 'sets': 864, 'wasteful': 865, 'debateth': 866, 'sullied': 867, 'engraft': 868, 'xvi': 869, 'wherefore': 870, 'mightier': 871, 'bloody': 872, 'tyrant': 873, 'fortify': 874, 'means': 875, 'top': 876, 'maiden': 877, 'gardens': 878, 'unset': 879, 'virtuous': 880, 'liker': 881, 'counterfeit': 882, 'pencil': 883, 'pupil': 884, 'neither': 885, 'inward': 886, 'outward': 887, 'keeps': 888, 'xvii': 889, \"fill'd\": 890, 'high': 891, 'deserts': 892, 'hides': 893, 'half': 894, 'number': 895, 'graces': 896, 'poet': 897, \"ne'er\": 898, \"touch'd\": 899, 'earthly': 900, 'faces': 901, 'papers': 902, \"yellow'd\": 903, \"scorn'd\": 904, 'rights': 905, \"term'd\": 906, \"poet's\": 907, 'stretched': 908, 'metre': 909, 'alive': 910, 'twice': 911, 'xviii': 912, 'temperate': 913, 'rough': 914, 'winds': 915, 'darling': 916, 'buds': 917, 'short': 918, 'hot': 919, 'often': 920, 'complexion': 921, \"dimm'd\": 922, 'declines': 923, 'chance': 924, 'changing': 925, \"untrimm'd\": 926, 'fade': 927, 'possession': 928, \"ow'st\": 929, 'brag': 930, \"wander'st\": 931, 'xix': 932, 'devouring': 933, 'blunt': 934, \"lion's\": 935, 'paws': 936, 'devour': 937, 'brood': 938, 'keen': 939, 'teeth': 940, \"tiger's\": 941, 'jaws': 942, 'burn': 943, \"liv'd\": 944, 'phoenix': 945, 'sorry': 946, 'seasons': 947, 'fleets': 948, \"whate'er\": 949, 'footed': 950, 'fading': 951, 'forbid': 952, 'heinous': 953, 'crime': 954, 'carve': 955, 'untainted': 956, 'allow': 957, 'pattern': 958, 'succeeding': 959, 'worst': 960, 'ever': 961, 'young': 962, 'xx': 963, 'master': 964, 'mistress': 965, 'passion': 966, 'acquainted': 967, 'shifting': 968, 'fashion': 969, 'rolling': 970, 'object': 971, 'whereupon': 972, 'gazeth': 973, 'hue': 974, \"'hues'\": 975, 'controlling': 976, 'steals': 977, 'souls': 978, 'amazeth': 979, 'wert': 980, 'created': 981, 'fell': 982, 'doting': 983, 'addition': 984, 'defeated': 985, 'adding': 986, \"prick'd\": 987, 'xxi': 988, \"stirr'd\": 989, 'itself': 990, 'couplement': 991, \"sea's\": 992, 'gems': 993, \"april's\": 994, 'born': 995, 'rare': 996, 'rondure': 997, 'hems': 998, 'truly': 999, 'candles': 1000, \"fix'd\": 1001, 'hearsay': 1002, 'sell': 1003, 'xxii': 1004, 'persuade': 1005, 'furrows': 1006, 'expiate': 1007, 'seemly': 1008, 'raiment': 1009, 'elder': 1010, 'wary': 1011, 'bearing': 1012, 'chary': 1013, 'nurse': 1014, 'babe': 1015, 'faring': 1016, 'presume': 1017, 'slain': 1018, \"gav'st\": 1019, 'xxiii': 1020, 'unperfect': 1021, 'actor': 1022, 'put': 1023, 'beside': 1024, 'replete': 1025, \"strength's\": 1026, 'weakens': 1027, 'trust': 1028, 'forget': 1029, 'perfect': 1030, 'ceremony': 1031, 'rite': 1032, 'strength': 1033, \"o'ercharg'd\": 1034, 'burthen': 1035, 'eloquence': 1036, 'presagers': 1037, 'speaking': 1038, 'plead': 1039, 'recompense': 1040, \"express'd\": 1041, 'learn': 1042, 'writ': 1043, 'belongs': 1044, 'fine': 1045, 'xxiv': 1046, \"play'd\": 1047, \"stell'd\": 1048, 'table': 1049, 'body': 1050, 'wherein': 1051, 'perspective': 1052, \"painter's\": 1053, \"pictur'd\": 1054, \"bosom's\": 1055, 'shop': 1056, 'hanging': 1057, 'glazed': 1058, 'turns': 1059, 'peep': 1060, 'therein': 1061, 'cunning': 1062, 'xxv': 1063, 'favour': 1064, 'titles': 1065, 'triumph': 1066, 'bars': 1067, \"princes'\": 1068, 'favourites': 1069, 'spread': 1070, 'marigold': 1071, \"sun's\": 1072, 'pride': 1073, 'frown': 1074, 'painful': 1075, 'warrior': 1076, 'famoused': 1077, 'fight': 1078, 'thousand': 1079, 'victories': 1080, \"foil'd\": 1081, 'book': 1082, 'razed': 1083, 'forgot': 1084, \"toil'd\": 1085, 'remove': 1086, 'xxvi': 1087, 'lord': 1088, 'vassalage': 1089, 'merit': 1090, 'strongly': 1091, 'knit': 1092, 'written': 1093, 'embassage': 1094, 'witness': 1095, 'bare': 1096, 'wanting': 1097, 'words': 1098, 'naked': 1099, 'bestow': 1100, 'whatsoever': 1101, 'star': 1102, 'guides': 1103, 'moving': 1104, 'points': 1105, 'graciously': 1106, 'aspect': 1107, 'puts': 1108, 'apparel': 1109, 'dare': 1110, 'xxvii': 1111, 'haste': 1112, 'bed': 1113, 'respose': 1114, \"tir'd\": 1115, 'begins': 1116, 'journey': 1117, \"body's\": 1118, \"work's\": 1119, 'expired': 1120, 'intend': 1121, 'zealous': 1122, 'drooping': 1123, 'eyelids': 1124, 'open': 1125, 'darkness': 1126, 'blind': 1127, 'imaginary': 1128, 'presents': 1129, 'jewel': 1130, 'ghastly': 1131, 'makes': 1132, 'black': 1133, 'quiet': 1134, 'xxviii': 1135, 'return': 1136, 'plight': 1137, \"debarre'd\": 1138, 'benefit': 1139, \"day's\": 1140, 'oppression': 1141, \"eas'd\": 1142, 'enemies': 1143, 'reign': 1144, 'consent': 1145, 'hands': 1146, 'torture': 1147, 'complain': 1148, 'farther': 1149, 'off': 1150, 'blot': 1151, 'swart': 1152, \"complexion'd\": 1153, 'sparkling': 1154, 'twire': 1155, \"gild'st\": 1156, 'daily': 1157, 'nightly': 1158, \"grief's\": 1159, 'length': 1160, 'stronger': 1161, 'xxix': 1162, 'beweep': 1163, 'outcast': 1164, 'trouble': 1165, 'deaf': 1166, 'bootless': 1167, 'cries': 1168, 'curse': 1169, 'fate': 1170, 'wishing': 1171, \"featur'd\": 1172, 'desiring': 1173, 'scope': 1174, 'enjoy': 1175, 'almost': 1176, 'despising': 1177, 'haply': 1178, 'lark': 1179, 'arising': 1180, 'sullen': 1181, 'hymns': 1182, 'gate': 1183, 'brings': 1184, 'scorn': 1185, 'kings': 1186, 'xxx': 1187, 'sessions': 1188, 'summon': 1189, 'sigh': 1190, 'lack': 1191, 'sought': 1192, 'woes': 1193, 'drown': 1194, 'flow': 1195, 'precious': 1196, 'hid': 1197, 'dateless': 1198, 'afresh': 1199, \"cancell'd\": 1200, 'expense': 1201, \"vanish'd\": 1202, 'grieve': 1203, 'grievances': 1204, 'foregone': 1205, 'heavily': 1206, 'account': 1207, 'fore': 1208, 'bemoaned': 1209, 'paid': 1210, 'losses': 1211, \"restor'd\": 1212, 'xxxi': 1213, 'endeared': 1214, 'hearts': 1215, 'lacking': 1216, 'supposed': 1217, 'reigns': 1218, 'holy': 1219, 'obsequious': 1220, 'tear': 1221, 'religious': 1222, \"stol'n\": 1223, 'interest': 1224, 'appear': 1225, 'hidden': 1226, 'lie': 1227, 'trophies': 1228, 'lovers': 1229, 'images': 1230, \"lov'd\": 1231, 'xxxii': 1232, 'survive': 1233, 'bones': 1234, 'dust': 1235, 're': 1236, 'survey': 1237, 'deceased': 1238, 'lover': 1239, \"bett'ring\": 1240, \"outstripp'd\": 1241, 'reserve': 1242, 'exceeded': 1243, 'vouchsafe': 1244, \"'had\": 1245, \"friend's\": 1246, 'grown': 1247, 'growing': 1248, 'dearer': 1249, 'march': 1250, 'ranks': 1251, 'equipage': 1252, 'died': 1253, 'poets': 1254, 'style': 1255, \"i'll\": 1256, \"love'\": 1257, 'xxxiii': 1258, 'glorious': 1259, 'morning': 1260, 'seen': 1261, 'mountain': 1262, 'tops': 1263, 'sovereign': 1264, 'kissing': 1265, 'meadows': 1266, 'pale': 1267, 'streams': 1268, 'alchemy': 1269, 'anon': 1270, 'permit': 1271, 'basest': 1272, 'ride': 1273, 'ugly': 1274, 'rack': 1275, 'celestial': 1276, 'forlorn': 1277, 'visage': 1278, 'hide': 1279, 'stealing': 1280, 'unseen': 1281, 'west': 1282, 'early': 1283, 'morn': 1284, 'shine': 1285, 'triumphant': 1286, 'splendour': 1287, 'alack': 1288, 'hour': 1289, 'region': 1290, \"mask'd\": 1291, 'whit': 1292, 'disdaineth': 1293, 'suns': 1294, 'staineth': 1295, 'xxxiv': 1296, 'didst': 1297, 'promise': 1298, 'cloak': 1299, 'base': 1300, \"o'ertake\": 1301, 'hiding': 1302, 'bravery': 1303, 'rotten': 1304, 'smoke': 1305, 'enough': 1306, 'dry': 1307, 'storm': 1308, 'beaten': 1309, 'salve': 1310, 'speak': 1311, 'heals': 1312, 'wound': 1313, 'cures': 1314, 'physic': 1315, 'repent': 1316, \"offender's\": 1317, 'sorrow': 1318, 'weak': 1319, 'relief': 1320, 'bears': 1321, \"offence's\": 1322, 'pearl': 1323, 'sheds': 1324, 'ransom': 1325, 'xxxv': 1326, \"griev'd\": 1327, 'roses': 1328, 'thorns': 1329, 'silver': 1330, 'fountains': 1331, 'mud': 1332, 'eclipses': 1333, 'loathsome': 1334, 'canker': 1335, 'sweetest': 1336, 'faults': 1337, 'authorizing': 1338, 'trespass': 1339, 'corrupting': 1340, 'salving': 1341, 'amiss': 1342, 'excusing': 1343, 'sensual': 1344, 'fault': 1345, 'sense': 1346, 'adverse': 1347, 'party': 1348, 'advocate': 1349, 'lawful': 1350, 'plea': 1351, 'commence': 1352, 'civil': 1353, 'accessary': 1354, 'needs': 1355, 'robs': 1356, 'xxxvi': 1357, 'confess': 1358, 'undivided': 1359, 'blots': 1360, 'help': 1361, 'separable': 1362, 'alter': 1363, 'sole': 1364, 'evermore': 1365, 'acknowledge': 1366, 'lest': 1367, 'bewailed': 1368, 'guilt': 1369, 'kindness': 1370, 'sort': 1371, 'report': 1372, 'xxxvii': 1373, 'decrepit': 1374, 'active': 1375, \"fortune's\": 1376, 'dearest': 1377, 'comfort': 1378, 'whether': 1379, 'entitled': 1380, 'crowned': 1381, 'sit': 1382, 'engrafted': 1383, \"despis'd\": 1384, \"suffic'd\": 1385, 'xxxviii': 1386, 'subject': 1387, 'invent': 1388, \"pour'st\": 1389, 'into': 1390, 'argument': 1391, 'excellent': 1392, 'vulgar': 1393, 'paper': 1394, 'thanks': 1395, 'aught': 1396, 'perusal': 1397, \"who's\": 1398, 'invention': 1399, 'tenth': 1400, 'nine': 1401, 'rhymers': 1402, 'invocate': 1403, 'outlive': 1404, 'curious': 1405, 'pain': 1406, 'xxxix': 1407, 'manners': 1408, \"is't\": 1409, 'us': 1410, 'divided': 1411, 'separation': 1412, \"deserv'st\": 1413, 'absence': 1414, 'torment': 1415, 'sour': 1416, 'entertain': 1417, 'teachest': 1418, 'praising': 1419, 'xl': 1420, 'yea': 1421, 'receivest': 1422, 'blame': 1423, 'usest': 1424, \"blam'd\": 1425, 'deceivest': 1426, 'wilful': 1427, 'taste': 1428, 'refusest': 1429, 'forgive': 1430, 'robbery': 1431, 'poverty': 1432, 'greater': 1433, \"hate's\": 1434, 'known': 1435, 'injury': 1436, 'lascivious': 1437, 'kill': 1438, 'spites': 1439, 'foes': 1440, 'xli': 1441, 'pretty': 1442, 'wrongs': 1443, 'liberty': 1444, 'years': 1445, 'befits': 1446, 'temptation': 1447, 'follows': 1448, 'won': 1449, \"assail'd\": 1450, 'woos': 1451, \"prevail'd\": 1452, 'ay': 1453, 'mightst': 1454, 'seat': 1455, 'forbear': 1456, 'straying': 1457, 'lead': 1458, 'riot': 1459, 'forced': 1460, 'twofold': 1461, 'hers': 1462, 'tempting': 1463, 'xlii': 1464, 'said': 1465, 'loved': 1466, 'dearly': 1467, 'wailing': 1468, 'nearly': 1469, 'offenders': 1470, 'ye': 1471, 'because': 1472, \"know'st\": 1473, 'suffering': 1474, 'approve': 1475, 'gain': 1476, 'losing': 1477, 'found': 1478, 'lay': 1479, \"here's\": 1480, 'flattery': 1481, 'xliii': 1482, 'wink': 1483, 'unrespected': 1484, 'darkly': 1485, 'dark': 1486, 'directed': 1487, 'shadows': 1488, \"shadow's\": 1489, 'clear': 1490, 'clearer': 1491, 'unseeing': 1492, 'imperfect': 1493, 'xliv': 1494, 'dull': 1495, 'flesh': 1496, 'injurious': 1497, 'distance': 1498, 'space': 1499, 'limits': 1500, 'remote': 1501, 'matter': 1502, 'foot': 1503, 'farthest': 1504, 'nimble': 1505, 'jump': 1506, 'sea': 1507, 'land': 1508, 'soon': 1509, 'kills': 1510, 'leap': 1511, 'large': 1512, 'lengths': 1513, 'miles': 1514, 'water': 1515, 'attend': 1516, 'receiving': 1517, 'slow': 1518, 'badges': 1519, 'xlv': 1520, 'purging': 1521, 'fire': 1522, 'wherever': 1523, 'present': 1524, 'motion': 1525, 'slide': 1526, 'quicker': 1527, 'embassy': 1528, 'four': 1529, 'sinks': 1530, 'down': 1531, 'melancholy': 1532, 'until': 1533, \"life's\": 1534, 'composition': 1535, \"recur'd\": 1536, 'messengers': 1537, \"return'd\": 1538, \"assur'd\": 1539, 'health': 1540, 'recounting': 1541, 'told': 1542, 'straight': 1543}\n",
      "1544\n"
     ]
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "##calculate vocabulary size - be mindful of the <oov> token\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3uEYLlk8ra-O"
   },
   "outputs": [],
   "source": [
    "##create sequences of \n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    tokens = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(tokens)):\n",
    "        n_gram_sequence = tokens[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1zzrLngux8Bd"
   },
   "outputs": [],
   "source": [
    "##pad sequences\n",
    "max_seq_len = max([len(i) for i in input_sequences])\n",
    "input_seq_array = np.array(pad_sequences(input_sequences,\n",
    "                                         maxlen=max_seq_len,\n",
    "                                         padding='pre')\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tTGbnKtG1zqD"
   },
   "outputs": [],
   "source": [
    "##creating features(X) and label(y)\n",
    "X = input_seq_array[:, :-1]\n",
    "labels = input_seq_array[:, -1]\n",
    "\n",
    "##one-hot encode the labels to get y - since it is actually just a classification problem\n",
    "y = tf.keras.utils.to_categorical(labels, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1zZGFrm3AsY"
   },
   "source": [
    "## Define the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95bU1pLN5c0s",
    "outputId": "80d228ce-b277-48e0-d268-958ab89928b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "142/142 [==============================] - 9s 8ms/step - loss: 4.3305 - accuracy: 0.3889\n",
      "Epoch 2/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.0080 - accuracy: 0.6763\n",
      "Epoch 3/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 0.9944 - accuracy: 0.7970\n",
      "Epoch 4/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 0.2311 - accuracy: 0.9498\n",
      "Epoch 5/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 0.0213 - accuracy: 0.9965\n",
      "Epoch 6/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.0367e-04 - accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 5.2391e-04 - accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 4.1690e-04 - accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 3.4362e-04 - accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.8959e-04 - accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.4835e-04 - accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.1560e-04 - accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.8901e-04 - accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.6717e-04 - accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.4886e-04 - accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.3328e-04 - accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.1989e-04 - accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.0831e-04 - accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 9.8176e-05 - accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.9284e-05 - accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.1442e-05 - accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.4479e-05 - accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 6.8202e-05 - accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 6.2596e-05 - accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 5.7549e-05 - accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 5.2998e-05 - accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 4.8860e-05 - accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 4.5102e-05 - accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 4.1686e-05 - accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 3.8561e-05 - accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 3.5694e-05 - accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 3.3079e-05 - accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 3.0672e-05 - accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.8454e-05 - accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.6426e-05 - accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.4539e-05 - accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.2803e-05 - accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.1192e-05 - accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.9713e-05 - accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.8332e-05 - accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.7071e-05 - accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.5888e-05 - accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.4798e-05 - accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.3776e-05 - accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.2833e-05 - accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.1962e-05 - accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.1144e-05 - accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.0392e-05 - accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 9.6789e-06 - accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 9.0278e-06 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.4110e-06 - accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.8400e-06 - accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.3169e-06 - accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 6.8257e-06 - accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 6.3637e-06 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 5.9318e-06 - accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 5.5351e-06 - accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 5.1573e-06 - accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 4.8094e-06 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 4.4896e-06 - accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 4.1909e-06 - accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 3.9123e-06 - accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 3.6471e-06 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 3.3989e-06 - accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 3.1705e-06 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.9527e-06 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.7529e-06 - accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.5731e-06 - accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.4023e-06 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.2400e-06 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.0930e-06 - accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.9547e-06 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.8222e-06 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.6999e-06 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.5892e-06 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.4876e-06 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.3905e-06 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.2965e-06 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.2079e-06 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.1299e-06 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.0536e-06 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 9.8378e-07 - accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 9.1809e-07 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.5640e-07 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.9978e-07 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.4528e-07 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 6.9513e-07 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 6.5202e-07 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 6.0974e-07 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 5.7311e-07 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 5.3642e-07 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 5.0099e-07 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 4.7015e-07 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 4.3967e-07 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 4.0883e-07 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 3.8310e-07 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 3.5955e-07 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 3.3801e-07 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 3.1791e-07 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.9958e-07 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.8225e-07 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.6634e-07 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.5048e-07 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.3739e-07 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.2480e-07 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.1182e-07 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 2.0039e-07 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "142/142 [==============================] - 1s 9ms/step - loss: 1.8972e-07 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.8179e-07 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.7347e-07 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.6467e-07 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.5498e-07 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.4871e-07 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.4249e-07 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.3686e-07 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.3106e-07 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.2690e-07 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.2219e-07 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.1805e-07 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.1360e-07 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.1033e-07 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.0686e-07 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.0359e-07 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.0064e-07 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 9.8323e-08 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 9.4556e-08 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 9.3845e-08 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 9.1369e-08 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.9499e-08 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.8209e-08 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.7708e-08 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.4916e-08 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.4363e-08 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.5575e-08 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "142/142 [==============================] - 1s 9ms/step - loss: 8.3046e-08 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "142/142 [==============================] - 1s 9ms/step - loss: 8.3152e-08 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.1150e-08 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.0913e-08 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.0544e-08 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.9754e-08 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.9596e-08 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.9596e-08 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.8569e-08 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.8384e-08 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.7594e-08 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.8490e-08 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.9122e-08 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.6988e-08 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.7778e-08 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.7067e-08 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.8674e-08 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.6883e-08 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.8911e-08 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.7199e-08 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.7620e-08 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.8279e-08 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.8094e-08 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.8358e-08 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.9306e-08 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.8332e-08 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.9438e-08 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.8779e-08 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.8648e-08 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.0544e-08 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.9122e-08 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.9332e-08 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.0886e-08 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 7.9991e-08 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.1413e-08 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.1650e-08 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.0386e-08 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.0755e-08 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.0439e-08 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.2045e-08 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.1202e-08 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.1202e-08 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.1703e-08 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.1018e-08 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.0807e-08 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.2230e-08 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.2072e-08 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.2546e-08 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.2440e-08 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.2598e-08 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.3547e-08 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.0939e-08 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.2440e-08 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "142/142 [==============================] - 1s 9ms/step - loss: 8.2572e-08 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.2862e-08 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.2230e-08 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.3573e-08 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.1545e-08 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.2809e-08 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.3599e-08 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.2045e-08 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.3520e-08 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.2309e-08 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.2783e-08 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 8.1729e-08 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Embedding(vocab_size, 120, input_length=max_seq_len-1),\n",
    "                tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(120)),\n",
    "                tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "##define the learning rate - step size for optimizer\n",
    "adam = tf.keras.optimizers.Adam(lr=0.01)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "history = model.fit(X, y, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dlL32NS3FnM"
   },
   "source": [
    "## Visualise the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tc7nqPbg5tBy"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_metric(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "hHHODnWIrobv",
    "outputId": "17b9e6b4-1713-4e1f-e8fe-c1c21061bb20"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VxJduva3IR-"
   },
   "source": [
    "## Generate new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db3z5YdkrtXI",
    "outputId": "d53ec3b4-2ed0-4d09-ccd2-366f38922810"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a cold night. a\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"It was a cold night.\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "\ttoken_list = pad_sequences([token_list], maxlen=max_seq_len-1, padding='pre')\n",
    "predicted_x = model.predict(token_list, verbose=0)\n",
    "predicted = np.argmax(predicted_x, axis = 1)\n",
    "output_word = \"\"\n",
    "for word, index in tokenizer.word_index.items():\n",
    "\tif index == predicted:\n",
    "\t\toutput_word = word\n",
    "\t\tbreak\n",
    "seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBaccPocsJWP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "04_03_challenge.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
